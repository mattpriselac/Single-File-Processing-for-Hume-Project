{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from functions_and_classes.treatise_reference_data import treatise_paragraph_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_and_classes.paper_processing import chapterScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_and_classes.classes import *\n",
    "from functions_and_classes.paper_io import p_to_dict, p_from_dict, c_to_dict, c_from_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.jsons import json_list\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_w_p_reverse = {}\n",
    "s_w_p_reverse = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1375\n",
      "1375\n"
     ]
    }
   ],
   "source": [
    "for para in treatise_paragraph_list:\n",
    "    a_w_p_reverse[para] = 0\n",
    "    s_w_p_reverse[para] = 0\n",
    "print(len(a_w_p_reverse.keys()))\n",
    "print(len(s_w_p_reverse.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n",
      "93\n"
     ]
    }
   ],
   "source": [
    "a_w_c_reverse = chapterScores(a_w_p_reverse)\n",
    "s_w_c_reverse = chapterScores(s_w_p_reverse)\n",
    "print(len(a_w_c_reverse.keys()))\n",
    "print(len(s_w_c_reverse.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "awprev_df = pd.DataFrame.from_dict(a_w_p_reverse, orient='index', columns=['Blank'])\n",
    "awcrev_df = pd.DataFrame.from_dict(a_w_c_reverse, orient='index', columns=['Blank'])\n",
    "swprev_df = pd.DataFrame.from_dict(s_w_p_reverse, orient='index', columns=['Blank'])\n",
    "swcrev_df = pd.DataFrame.from_dict(s_w_c_reverse, orient='index', columns=['Blank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.1.1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.1.2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.1.3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.1.4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.3.4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.3.5</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.3.6</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>App.</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abs</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Blank\n",
       "0          0\n",
       "1.1.1      0\n",
       "1.1.2      0\n",
       "1.1.3      0\n",
       "1.1.4      0\n",
       "...      ...\n",
       "3.3.4      0\n",
       "3.3.5      0\n",
       "3.3.6      0\n",
       "App.       0\n",
       "Abs        0\n",
       "\n",
       "[93 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the blanks\n",
    "awprev_df = pd.DataFrame.from_dict(a_w_p_reverse, orient='index', columns=['Blank'])\n",
    "awcrev_df = pd.DataFrame.from_dict(a_w_c_reverse, orient='index', columns=['Blank'])\n",
    "swprev_df = pd.DataFrame.from_dict(s_w_p_reverse, orient='index', columns=['Blank'])\n",
    "swcrev_df = pd.DataFrame.from_dict(s_w_c_reverse, orient='index', columns=['Blank'])\n",
    "#fill them with the article data\n",
    "for file in json_list:\n",
    "    #create the paper object\n",
    "    jf = open('data/jsons/'+file, 'r')\n",
    "    jd = json.load(jf)\n",
    "    jf.close()\n",
    "    pawp = pd.DataFrame.from_dict(jd['a_w_p'], orient='index', columns=[file[:-5]])\n",
    "    awprev_df[file[:-5]] = pawp[file[:-5]]\n",
    "    pawc = pd.DataFrame.from_dict(jd['a_w_c'], orient='index', columns=[file[:-5]])\n",
    "    awcrev_df[file[:-5]] = pawc[file[:-5]]\n",
    "    pswp = pd.DataFrame.from_dict(jd['s_w_p'], orient='index', columns=[file[:-5]])\n",
    "    swprev_df[file[:-5]] = pswp[file[:-5]]\n",
    "    pswc = pd.DataFrame.from_dict(jd['s_w_c'], orient='index', columns=[file[:-5]])\n",
    "    swcrev_df[file[:-5]] = pswc[file[:-5]]\n",
    "#delete the blanks\n",
    "del awprev_df['Blank']\n",
    "del awcrev_df['Blank']\n",
    "del swprev_df['Blank']\n",
    "del swcrev_df['Blank']\n",
    "#generate csvs\n",
    "awprev_df.to_csv('data/awpreverse.csv')\n",
    "awcrev_df.to_csv('data/awcreverse.csv')\n",
    "swprev_df.to_csv('data/swpreverse.csv')\n",
    "swcrev_df.to_csv('data/swcreverse.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "533Cottrell                                                            10.836\n",
       "31448-231447-1-PB                                                      10.000\n",
       "strawson-evident-connexion                                              9.000\n",
       "ROCHAT-4v1                                                              4.366\n",
       "1173780                                                                 4.001\n",
       "project_muse_389389                                                     3.499\n",
       "project_muse_553401                                                     3.000\n",
       "out                                                                     3.000\n",
       "Kail-2008-European_Journal_of_Philosophy                                2.000\n",
       "project_muse_390704                                                     2.000\n",
       "24439665                                                                2.000\n",
       "project_muse_383238                                                     2.000\n",
       "project_muse_511194                                                     1.836\n",
       "project_muse_403836                                                     1.666\n",
       "20532746                                                                1.246\n",
       "41441496                                                                1.000\n",
       "project_muse_382933                                                     1.000\n",
       "07.0_pp_177_208_Hume_and_the_Problem_of_Personal_Identity               1.000\n",
       "acprof-9780199229505-chapter-6                                          1.000\n",
       "40232176                                                                1.000\n",
       "ContentServer.asp-4                                                     1.000\n",
       "project_muse_388443                                                     0.999\n",
       "acpq_1995_0069_0003_0485_0501&pdfname=acpq_1995_0069_0003_0091_0107     0.999\n",
       "Projection and Realism in Hume's Philosophy coventry review             0.999\n",
       "project_muse_382726                                                     0.994\n",
       "2184977                                                                 0.666\n",
       "thiel-early-modern-self-13-14                                           0.500\n",
       "fshow                                                                   0.334\n",
       "Name: 1.1.1, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now let's create usable dictionaries \n",
    "awc111rev = awcrev_df.loc['1.1.1']\n",
    "zfilter = awc111rev > 0\n",
    "awc111revsc = awc111rev[zfilter].sort_values(ascending=False)\n",
    "awc111revsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def locationFrequency(location, df):\n",
    "    location_series = df.loc[location]\n",
    "    zfilter = location_series > 0\n",
    "    csloc_series = location_series[zfilter].sort_values(ascending=False)\n",
    "    \n",
    "    out_list = []\n",
    "    \n",
    "    for article in csloc_series.index:\n",
    "        out_list.append((article,csloc_series.loc[article]))\n",
    "\n",
    "    return out_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('533Cottrell', 38.57),\n",
       " ('project_muse_553401', 12.999),\n",
       " ('strawson-evident-connexion', 10.5),\n",
       " ('Kail-2008-European_Journal_of_Philosophy', 4.9990000000000006),\n",
       " ('1173636', 4.0),\n",
       " ('project_muse_228761', 2.0),\n",
       " ('acprof-9780199229505-chapter-6', 2.0),\n",
       " ('project_muse_596651', 1.0010000000000001),\n",
       " ('41441496', 1.0),\n",
       " ('project_muse_439820', 0.9990000000000001),\n",
       " ('project_muse_388507', 0.9990000000000001)]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locationFrequency('Abs', awcrev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To select a paragraph or chapter, it'll help to have selection menus to work with. Book, Section, Chapter, Paragraph.\n",
    "#I'll have to do some work to narrow those down.\n",
    "#Set it up such that you must select at least a chapter but if you don't select a paragraph you'll just get the list for the whole chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a dictionary \n",
    "loc_dict = {}\n",
    "books = ['Abstract', 'Introduction', 'I', 'II', 'III', 'Appendix']\n",
    "sections = []\n",
    "chapters = []\n",
    "paragraphs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " 'App',\n",
       " 'Absi',\n",
       " 'Absii',\n",
       " 'Absiii',\n",
       " 'Absiv',\n",
       " 'Abs1',\n",
       " 'Abs2',\n",
       " 'Abs3',\n",
       " 'Abs4',\n",
       " 'Abs5',\n",
       " 'Abs6',\n",
       " 'Abs7',\n",
       " 'Abs8',\n",
       " 'Abs9',\n",
       " 'Abs10',\n",
       " 'Abs11',\n",
       " 'Abs12',\n",
       " 'Abs13',\n",
       " 'Abs14',\n",
       " 'Abs15',\n",
       " 'Abs16',\n",
       " 'Abs17',\n",
       " 'Abs18',\n",
       " 'Abs19',\n",
       " 'Abs20',\n",
       " 'Abs21',\n",
       " 'Abs22',\n",
       " 'Abs23',\n",
       " 'Abs24',\n",
       " 'Abs25',\n",
       " 'Abs26',\n",
       " 'Abs27',\n",
       " 'Abs28',\n",
       " 'Abs29',\n",
       " 'Abs30',\n",
       " 'Abs31',\n",
       " 'Abs32',\n",
       " 'Abs33',\n",
       " 'Abs34',\n",
       " 'Abs35']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_list=[]\n",
    "for loc in treatise_paragraph_list:\n",
    "    structure_loc = loc.split('.')\n",
    "   #create a book list:\n",
    "    if structure_loc[0] not in book_list:\n",
    "        book_list.append(structure_loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "chap_list = []\n",
    "book_sect_dict = {}\n",
    "for book in book_list:\n",
    "    section_list = []\n",
    "    for loc in treatise_paragraph_list:\n",
    "        struct_loc = loc.split('.')\n",
    "        if struct_loc[0] == book and struct_loc[1] not in section_list:\n",
    "            section_list.append(struct_loc[1])\n",
    "    book_sect_dict[book] = section_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '7n1']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_sect_dict['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " '1.1.1',\n",
       " '1.1.2',\n",
       " '1.1.3',\n",
       " '1.1.4',\n",
       " '1.1.5',\n",
       " '1.1.6',\n",
       " '1.1.7',\n",
       " '1.2.1',\n",
       " '1.2.2',\n",
       " '1.2.3',\n",
       " '1.2.4',\n",
       " '1.2.5',\n",
       " '1.2.6',\n",
       " '1.3.1',\n",
       " '1.3.2',\n",
       " '1.3.3',\n",
       " '1.3.4',\n",
       " '1.3.5',\n",
       " '1.3.6',\n",
       " '1.3.7',\n",
       " '1.3.8',\n",
       " '1.3.9',\n",
       " '1.3.10',\n",
       " '1.3.11',\n",
       " '1.3.12',\n",
       " '1.3.13',\n",
       " '1.3.14',\n",
       " '1.3.15',\n",
       " '1.3.16',\n",
       " '1.4.1',\n",
       " '1.4.2',\n",
       " '1.4.3',\n",
       " '1.4.4',\n",
       " '1.4.5',\n",
       " '1.4.6',\n",
       " '1.4.7',\n",
       " '2.1.1',\n",
       " '2.1.2',\n",
       " '2.1.3',\n",
       " '2.1.4',\n",
       " '2.1.5',\n",
       " '2.1.6',\n",
       " '2.1.7',\n",
       " '2.1.8',\n",
       " '2.1.9',\n",
       " '2.1.10',\n",
       " '2.1.11',\n",
       " '2.1.12',\n",
       " '2.2.1',\n",
       " '2.2.2',\n",
       " '2.2.3',\n",
       " '2.2.4',\n",
       " '2.2.5',\n",
       " '2.2.6',\n",
       " '2.2.7',\n",
       " '2.2.8',\n",
       " '2.2.9',\n",
       " '2.2.10',\n",
       " '2.2.11',\n",
       " '2.2.12',\n",
       " '2.3.1',\n",
       " '2.3.2',\n",
       " '2.3.3',\n",
       " '2.3.4',\n",
       " '2.3.5',\n",
       " '2.3.6',\n",
       " '2.3.7',\n",
       " '2.3.8',\n",
       " '2.3.9',\n",
       " '2.3.10',\n",
       " '3.1.1',\n",
       " '3.1.2',\n",
       " '3.2.1',\n",
       " '3.2.2',\n",
       " '3.2.3',\n",
       " '3.2.4',\n",
       " '3.2.5',\n",
       " '3.2.6',\n",
       " '3.2.7',\n",
       " '3.2.8',\n",
       " '3.2.9',\n",
       " '3.2.10',\n",
       " '3.2.11',\n",
       " '3.2.12',\n",
       " '3.3.1',\n",
       " '3.3.2',\n",
       " '3.3.3',\n",
       " '3.3.4',\n",
       " '3.3.5',\n",
       " '3.3.6',\n",
       " 'App.',\n",
       " 'Abs']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chap_list = []\n",
    "chapter_pattern = re.compile(r'(Abs)|(App\\.)|(0)|(\\d\\.\\d\\.\\d{1,2})')\n",
    "for para in treatise_paragraph_list:\n",
    "    chap_match = chapter_pattern.match(para).group()\n",
    "    if chap_match not in chap_list:\n",
    "        chap_list.append(chap_match)\n",
    "chap_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.1', '1.2', '1.3', '1.4', '2.1', '2.2', '2.3', '3.1', '3.2', '3.3']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_list = []\n",
    "section_pattern = re.compile(r'\\d\\.\\d{1,2}')\n",
    "for chapter in chap_list:\n",
    "    sect_match = section_pattern.match(chapter)\n",
    "    if sect_match != None:\n",
    "        if sect_match.group() not in section_list:\n",
    "            section_list.append(sect_match.group())\n",
    "section_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intro case: 0.x\n",
    "#regular books: X.x.x.x \n",
    "#appendix: App.x\n",
    "#Abstract: Abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1', '2', '3', 'App', 'Abs']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_pattern = re.compile(r'0|[123]|(Abs)|(App)')\n",
    "book_list = []\n",
    "for para in treatise_paragraph_list:\n",
    "    if book_pattern.match(para) != None:\n",
    "        if book_pattern.match(para).group() not in book_list:\n",
    "            book_list.append(book_pattern.match(para).group())\n",
    "book_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1375\n",
      "1375\n"
     ]
    }
   ],
   "source": [
    "new_para_list = []\n",
    "for para in treatise_paragraph_list:\n",
    "    if para[:3]=='Abs':\n",
    "        old = para[3:]\n",
    "        new = 'Abs.'+old\n",
    "        new_para_list.append(new)\n",
    "    else:\n",
    "        new_para_list.append(para)\n",
    "print(len(treatise_paragraph_list))        \n",
    "print(len(new_para_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1', '2', '3', 'App', 'Abs']"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blist = []\n",
    "for para in new_para_list:\n",
    "    sp = para.split('.')\n",
    "    if sp[0] not in blist:\n",
    "        blist.append(sp[0])\n",
    "blist\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_s_dict = {}\n",
    "for book in blist:\n",
    "    b_s_dict[book] = []\n",
    "#the scope is off here. i'm doing this fresh from scratch with every paragraph...derp\n",
    "for para in new_para_list:\n",
    "    #create a list of sections with that book:\n",
    "    sp = para.split('.')\n",
    "    for book in blist:\n",
    "        if sp[0] == book and sp[1] not in b_s_dict[book]:\n",
    "            b_s_dict[book].append(sp[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '7n1'],\n",
       " '1': {'1': [], '2': [], '3': [], '4': []},\n",
       " '2': {'1': [], '2': [], '3': []},\n",
       " '3': {'1': [], '2': [], '3': []},\n",
       " 'App': ['1',\n",
       "  '2',\n",
       "  '3',\n",
       "  '4',\n",
       "  '5',\n",
       "  '6',\n",
       "  '7',\n",
       "  '8',\n",
       "  '9',\n",
       "  '10',\n",
       "  '11',\n",
       "  '12',\n",
       "  '13',\n",
       "  '14',\n",
       "  '15',\n",
       "  '16',\n",
       "  '17',\n",
       "  '18',\n",
       "  '19',\n",
       "  '20',\n",
       "  '21',\n",
       "  '22',\n",
       "  '20n89'],\n",
       " 'Abs': ['i',\n",
       "  'ii',\n",
       "  'iii',\n",
       "  'iv',\n",
       "  '1',\n",
       "  '2',\n",
       "  '3',\n",
       "  '4',\n",
       "  '5',\n",
       "  '6',\n",
       "  '7',\n",
       "  '8',\n",
       "  '9',\n",
       "  '10',\n",
       "  '11',\n",
       "  '12',\n",
       "  '13',\n",
       "  '14',\n",
       "  '15',\n",
       "  '16',\n",
       "  '17',\n",
       "  '18',\n",
       "  '19',\n",
       "  '20',\n",
       "  '21',\n",
       "  '22',\n",
       "  '23',\n",
       "  '24',\n",
       "  '25',\n",
       "  '26',\n",
       "  '27',\n",
       "  '28',\n",
       "  '29',\n",
       "  '30',\n",
       "  '31',\n",
       "  '32',\n",
       "  '33',\n",
       "  '34',\n",
       "  '35']}"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_s_c_dict = {}\n",
    "for book in blist:\n",
    "    if book == \"App\" or book == \"Abs\" or book == \"0\":\n",
    "        b_s_c_dict[book] = b_s_dict[book]\n",
    "    else:\n",
    "        b_s_c_dict[book] = {}\n",
    "        for sect in b_s_dict[book]:\n",
    "            b_s_c_dict[book][sect] = []\n",
    "b_s_c_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "for para in new_para_list:\n",
    "    sp = para.split('.')\n",
    "    if len(sp) > 2:\n",
    "        for book in b_s_c_dict.keys():\n",
    "            if type(b_s_c_dict[book])==dict:\n",
    "                for sect in b_s_c_dict[book].keys():\n",
    "                    if (sp[0] == book and sp[1] == sect) and sp[2] not in b_s_c_dict[book][sect]:\n",
    "                        b_s_c_dict[book][sect].append(sp[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "bscp = {}\n",
    "for book in b_s_c_dict.keys():\n",
    "    if book == \"Abs\" or book == \"App\" or book == \"0\":\n",
    "        bscp[book] = b_s_c_dict[book]\n",
    "    else:\n",
    "        bscp[book] = {}\n",
    "        for sect in b_s_c_dict[book].keys():\n",
    "            bscp[book][sect] = {}\n",
    "            for chapter in b_s_c_dict[book][sect]:\n",
    "                bscp[book][sect][chapter] = []\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "for para in new_para_list:\n",
    "    sp = para.split('.')\n",
    "    if len(sp) > 2:\n",
    "        for book in bscp.keys():\n",
    "            if type(bscp[book])==dict:\n",
    "                for sect in bscp[book].keys():\n",
    "                    for chap in bscp[book][sect].keys():\n",
    "                        if (sp[0]==book and sp[1]==sect and sp[2]==chap) and sp[3] not in bscp[book][sect][chap]:\n",
    "                            bscp[book][sect][chap].append(sp[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "jf = open(\"data/treatise_structure_dict.json\", 'w')\n",
    "json.dump(bscp, jf)\n",
    "jf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['0', '1', '2', '3', 'App', 'Abs'])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testload = open('data/treatise_structure_dict.json', 'r')\n",
    "td = json.load(testload)\n",
    "testload.close()\n",
    "td.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['1', '2', '3', '4', '5', '6', '7'])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#okay now that i have this structure I can write the form selector page to generate the pages i'm interested in.\n",
    "td['1']['4'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
